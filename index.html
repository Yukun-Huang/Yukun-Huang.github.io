<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FEB9HPVWZK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FEB9HPVWZK');
</script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 600
    }
    name {
    font-family: 'Lato', Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="./assets/icon.jpg">
  <title>Yukun Huang - Homepage</title>
  
  <link href="css" rel="stylesheet" type="text/css">
  <style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style>

</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody><tr><td>
      <!-- Bio -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <!-- Description -->
          <td width="72%" valign="middle">
            <p align="center"><name>Yukun Huang (黄宇坤)</name></p>
            <p>I'm currently a postdoctoral fellow at the Institute of Data Science (IDS), <a href="https://www.hku.hk/">University of Hong Kong</a>, advised by Prof. <a href="https://xh-liu.github.io/">Xihui Liu</a> and Prof. <a href="https://www.cs.hku.hk/index.php/people/academic-staff/mayi">Yi Ma</a>.</p>
            <p>Before that, I obtained my Ph.D. from <a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a> (中国科学技术大学) in 2023, supervised by Prof. <a href="https://xueyangfu.github.io/">Xueyang Fu</a> and Prof. <a href="https://en.auto.ustc.edu.cn/2021/0616/c26828a513174/page.htm">Zheng-Jun Zha</a>.
               I also gained valuable experience working at <a href="https://www.idea.edu.cn/">International Digital Economy Academy (IDEA)</a>, <a href="https://arc.tencent.com/">Tencent ARC Lab</a>, and <a href="https://github.com/TencentYoutuResearch">Tencent Youtu Lab</a>.
            <p align="center">
              <a href="mailto:kunh6414@gmail.com">Email</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=lHb5gzoAAAAJ">Scholar</a> &nbsp;/&nbsp;
              <a href="https://github.com/Yukun-Huang">GitHub</a> &nbsp;/&nbsp;
              <a href="https://x.com/yukun6414">X (Twitter)</a>
              <!-- <a href="">CV</a> -->
            </p>
          </td>
          <!-- Photo -->
          <td width="28%">
            <img src="./assets/portrait.jpg" width="85%">
          </td>
        </tr></tbody>
      </table>
      
      <!-- Research -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td width="100%" valign="middle">
            <heading>Research</heading>
            <p>
              My research centers on computer vision, graphics, and machine learning, including 3D and video generation, pedestrian and object recognition, and low-level vision.
            </p>
            <p>
              I am particularly interested in <strong>3D generation</strong> of objects, avatars, and scenes, with the ultimate goal of creating immersive and fantastic digital worlds.
            </p>
          </td>
        </tr></tbody>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="margin-bottom: -20px;">
        <tbody><tr><td width="100%"><heading>Recent Publications</td></heading></tr></tbody>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <!-- Research: DreamCube -->
        <tr onmouseout="DreamCube_stop()" onmouseover="DreamCube_start()">
          <td width="25%">
            <div class="one">
              <div class="two" id='DreamCube_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/DreamCube.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/DreamCube.jpg" width="160">
            </div>
            <script type="text/javascript">
              function DreamCube_start() {
                  document.getElementById('DreamCube_video').style.opacity = "1";
              }
              function DreamCube_stop() {
                  document.getElementById('DreamCube_video').style.opacity = "0";
              }
              DreamCube_stop()
            </script>
          </td>
          <td width="75%">
            <p>
              <a href="https://yukun-huang.github.io/DreamCube/">
              <papertitle>DreamCube: 3D Panorama Generation via Multi-plane Synchronization</papertitle></a><br> 
              <strong>Yukun Huang</strong>, <a href="https://ynzhou.netlify.app/">Yanning Zhou</a>, <a href="https://github.com/wendyjnwang">Jianan Wang</a>, <a href="https://scholar.google.com/citations?user=dB86D_cAAAAJ">Kaiyi Huang</a>, <a href="https://xh-liu.github.io/">Xihui Liu</a><br>
              <em>ICCV 2025</em><br>
              <a href="https://yukun-huang.github.io/DreamCube/">project page</a> /
              <a href="https://arxiv.org/abs/2506.17206">arXiv</a> /
              <a href="https://github.com/yukun-huang/DreamCube">code</a> /
              <a href="https://huggingface.co/KevinHuang/DreamCube">model</a> /
              <a href="https://www.youtube.com/watch?v=7x4Elc2tO6g">video</a>
            </p>
            <p> RGB-D cubemap generation using pre-trained 2D diffusion and multi-plane synchronized operators, with applications in panoramic depth estimation and 3D scene synthesis.</p>
          </td>
        </tr>

        <!-- Research: DreamWaltz-G -->
        <tr onmouseout="DreamWaltzG_stop()" onmouseover="DreamWaltzG_start()" bgcolor="#ffffd0">
          <td width="25%">
            <div class="one">
              <div class="two" id='DreamWaltzG_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/DreamWaltz-G.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/DreamWaltz-G.jpg" width="160">
            </div>
            <script type="text/javascript">
              function DreamWaltzG_start() {
                  document.getElementById('DreamWaltzG_video').style.opacity = "1";
              }
              function DreamWaltzG_stop() {
                  document.getElementById('DreamWaltzG_video').style.opacity = "0";
              }
              DreamWaltzG_stop()
            </script>
          </td>
          <td width="75%">
            <p>
              <a href="https://yukun-huang.github.io/DreamWaltz-G/">
              <papertitle>DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion</papertitle></a><br> 
              <strong>Yukun Huang</strong>, <a href="https://github.com/wendyjnwang">Jianan Wang</a>, <a href="https://ailingzeng.site/">Ailing Zeng</a>, <a href="https://en.auto.ustc.edu.cn/2021/0616/c26828a513174/page.htm">Zheng-Jun Zha</a>, <a href="https://www.leizhang.org/">Lei Zhang</a>, <a href="https://xh-liu.github.io/">Xihui Liu</a><br>
              <em>TPAMI 2025</em><br>
              <a href="https://yukun-huang.github.io/DreamWaltz-G/">project page</a> /
              <a href="https://arxiv.org/abs/2409.17145">arXiv</a> /
              <a href="https://github.com/yukun-huang/DreamWaltz-G">code</a> /
              <a href="https://huggingface.co/KevinHuang/DreamWaltz-G">model</a>
            </p>
            <p>Expressive full-body 3D avatar generation from 2D diffusion using hybrid 3D Gaussian avatar representation and skeleton-guided score distillation.</p>
          </td>
        </tr>
        
        <!-- Research: DreamComposer++ -->
        <tr>
          <td width="25%">
            <div class="one">
            <img src="./works/DreamComposer++.jpg" style="height: 100%;">
            </div>
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://arxiv.org/abs/2507.02299">
              <papertitle>DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation</papertitle></a><br> 
              Yunhan Yang, Shuo Chen, <strong>Yukun Huang</strong>, Xiaoyang Wu, Yuan-Chen Guo, Edmund Y. Lam, Hengshuang Zhao, Tong He, Xihui Liu<br>
              <em>TPAMI 2025</em><br>
              <a href="https://arxiv.org/abs/2507.02299">arXiv</a>
            </p>
            <p>Integrating multi-view conditions into image and video diffusion models to generate controllable novel views for 3D object reconstruction.</p>
          </td>
        </tr>

        <!-- Research: HoloPart -->
        <tr onmouseout="HoloPart_stop()" onmouseover="HoloPart_start()" bgcolor="#ffffd0">
          <td width="25%">
            <div class="one">
              <div class="two" id='HoloPart_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/HoloPart.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/HoloPart.jpg" width="160">
            </div>
            <script type="text/javascript">
              function HoloPart_start() {
                  document.getElementById('HoloPart_video').style.opacity = "1";
              }
              function HoloPart_stop() {
                  document.getElementById('HoloPart_video').style.opacity = "0";
              }
              HoloPart_stop()
            </script>
          </td>
          <td width="75%">
            <p>
              <a href="https://vast-ai-research.github.io/HoloPart/">
              <papertitle>HoloPart: Generative 3D Part Amodal Segmentation</papertitle></a><br> 
              Yunhan Yang, Yuan-Chen Guo, <strong>Yukun Huang</strong>, Zi-Xin Zou, Zhipeng Yu, Yangguang Li, Yan-Pei Cao, Xihui Liu<br>
              <em>arXiv 2025</em><br>
              <a href="https://vast-ai-research.github.io/HoloPart/">project page</a> /
              <a href="https://arxiv.org/abs/2504.07943">arXiv</a> /
              <a href="https://github.com/VAST-AI-Research/HoloPart">code</a> /
              <a href="https://huggingface.co/spaces/VAST-AI/HoloPart">demo</a>
            </p>
            <p>Decomposing a 3D shape into complete, semantically meaningful parts.</p>
          </td>
        </tr>
        
        <!-- Research: SAMPart3D -->
        <tr onmouseout="SAMPart3D_stop()" onmouseover="SAMPart3D_start()">
          <td width="25%">
            <div class="one">
              <div class="two" id='SAMPart3D_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/SAMPart3D.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/SAMPart3D.jpg" width="160">
            </div>
            <script type="text/javascript">
              function SAMPart3D_start() {
                  document.getElementById('SAMPart3D_video').style.opacity = "1";
              }
              function SAMPart3D_stop() {
                  document.getElementById('SAMPart3D_video').style.opacity = "0";
              }
              SAMPart3D_stop()
            </script>
          </td>
          <td width="75%">
            <p>
              <a href="https://yhyang-myron.github.io/SAMPart3D-website/">
              <papertitle>SAMPart3D: Segment Any Part in 3D Objects</papertitle></a><br> 
              Yunhan Yang, <strong>Yukun Huang</strong>, Yuan-Chen Guo, Liangjun Lu, Xiaoyang Wu, Edmund Y. Lam, Yan-Pei Cao, Xihui Liu<br>
              <em>arXiv 2024</em><br>
              <a href="https://yhyang-myron.github.io/SAMPart3D-website/">project page</a> /
              <a href="https://arxiv.org/abs/2411.07184v1">arXiv</a> /
              <a href="https://github.com/Pointcept/SAMPart3D">code</a> /
              <a href="https://huggingface.co/datasets/yhyang-myron/PartObjaverse-Tiny">dataset (PartObjaverse-Tiny)</a>
            </p>
            <p>Zero-shot, multi-granularity 3D part segmentation using vision foundation models to learn scalable, flexible 3D features without label sets.</p>
          </td>
        </tr>

        <!-- Research: DreamComposer -->
        <tr>
          <td width="25%">
            <div class="one">
            <img src="./works/DreamComposer.jpg" style="height: 100%;">
            </div>
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://yhyang-myron.github.io/DreamComposer/">
              <papertitle>DreamComposer: Controllable 3D Object Generation via Multi-View Conditions</papertitle></a><br> 
              Yunhan Yang, <strong>Yukun Huang</strong>, Xiaoyang Wu, Yuan-Chen Guo, Song-Hai Zhang, Hengshuang Zhao, Tong He, Xihui Liu<br>
              <em>CVPR 2024</em><br>
              <a href="https://yhyang-myron.github.io/DreamComposer/">project page</a> /
              <a href="https://arxiv.org/abs/2312.03611">arXiv</a> /
              <a href="https://github.com/yhyang-myron/DreamComposer">code</a> /
              <a href="https://connecthkuhk-my.sharepoint.com/:f:/g/personal/yhyang07_connect_hku_hk/EudgwZJnLUtBiSohahgiT-4BgVn7oGGyndRWxvh5wtLbmw?e=AudlzM">model</a> 
            </p>
            <p>Integrating multi-view conditions into pre-trained 2D diffusion models to generate controllable novel views for 3D object reconstruction.</p>
          </td>
        </tr>

        <!-- Research: DreamTime -->
        <tr bgcolor="#ffffd0">
          <td width="25%">
            <div class="one">
            <img src="./works/DreamTime.png" style="height: 100%;">
            </div>
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://arxiv.org/abs/2306.12422">
              <papertitle>DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation</papertitle></a><br> 
              <strong>Yukun Huang</strong>, <a href="https://github.com/wendyjnwang">Jianan Wang</a>, <a href="https://shiyukai26.github.io/info/">Yukai Shi</a>, <a href="https://github.com/TangYucopper">Boshi Tang</a>, <a href="https://scholar.google.com/citations?user=odjSydQAAAAJ">Xianbiao Qi</a>, <a href="https://www.leizhang.org/">Lei Zhang</a><br>
              <em>ICLR 2024</em><br>
              <a href="https://arxiv.org/abs/2306.12422">arXiv</a> /
              <a href="https://proceedings.iclr.cc/paper_files/paper/2024/hash/3cb18c3c31ff1b77b97f4512abd5e4a6-Abstract-Conference.html">paper</a>
            </p>
            <p>Analyzing the drawbacks of random timestep sampling in score distillation sampling (SDS) and proposing a non-increasing timestep sampling strategy.</p>
          </td>
        </tr>

        <!-- Research: TOSS -->
        <tr onmouseout="TOSS_stop()" onmouseover="TOSS_start()">
          <td width="25%">
            <div class="one">
              <div class="two" id='TOSS_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/TOSS.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/TOSS.jpg" width="160">
            </div>
            <script type="text/javascript">
              function TOSS_start() {
                  document.getElementById('TOSS_video').style.opacity = "1";
              }
              function TOSS_stop() {
                  document.getElementById('TOSS_video').style.opacity = "0";
              }
              TOSS_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://toss3d.github.io/">
              <papertitle>TOSS: High-quality Text-guided Novel View Synthesis from a Single Image</papertitle></a><br> 
              Yukai Shi, Jianan Wang, He Cao, Boshi Tang, Xianbiao Qi, Tianyu Yang, <strong>Yukun Huang</strong>, Shilong Liu, Lei Zhang, Heung-Yeung Shum<br>
              <em>ICLR 2024</em><br>
              <a href="https://toss3d.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2310.10644">arXiv</a> /
              <a href="https://github.com/IDEA-Research/TOSS">code</a> /
              <a href="https://drive.google.com/drive/folders/15URQHblOVi_7YXZtgdFpjZAlKsoHylsq?usp=sharing">model</a>
            </p>
            <p>Utilizing texts as semantic guidance to further constrain the solution space of NVS, and generates more plausible, controllable, multiview-consistent novel view images from a single image.</p>
          </td>
        </tr>

        <!-- Research: DreamWaltz -->
        <tr onmouseout="DreamWaltz_stop()" onmouseover="DreamWaltz_start()">
          <td width="25%">
            <div class="one">
              <div class="two" id='DreamWaltz_video'>
                  <video width=100% height=100% muted autoplay loop>
                  <source src="./works/DreamWaltz.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video>
              </div>
              <img src="./works/DreamWaltz.jpg" width="160">
            </div>
            <script type="text/javascript">
              function DreamWaltz_start() {
                  document.getElementById('DreamWaltz_video').style.opacity = "1";
              }
              function DreamWaltz_stop() {
                  document.getElementById('DreamWaltz_video').style.opacity = "0";
              }
              DreamWaltz_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://idea-research.github.io/DreamWaltz/">
              <papertitle>DreamWaltz: Make a Scene with Complex 3D Animatable Avatars</papertitle></a><br> 
              <strong>Yukun Huang</strong>, <a href="https://github.com/wendyjnwang">Jianan Wang</a>, <a href="https://ailingzeng.site/">Ailing Zeng</a>, <a href="https://github.com/CiaoHe">He Cao</a>, <a href="https://scholar.google.com/citations?user=odjSydQAAAAJ">Xianbiao Qi</a>, <a href="https://shiyukai26.github.io/info/">Yukai Shi</a>, <a href="https://en.auto.ustc.edu.cn/2021/0616/c26828a513174/page.htm">Zheng-Jun Zha</a>, <a href="https://www.leizhang.org/">Lei Zhang</a><br>
              <em>NeurIPS 2023</em><br>
              <a href="https://idea-research.github.io/DreamWaltz/">project page</a> /
              <a href="https://arxiv.org/abs/2305.12529">arXiv</a> /
              <a href="https://github.com/IDEA-Research/DreamWaltz">code</a> /
              <a href="https://nips.cc/virtual/2023/poster/71368">poster</a> /
              <a href="https://drive.google.com/drive/folders/19JnDQja4jZjHkHTBmLLppS6-Ic7Xv3nS?usp=sharing">gallery</a>
            </p>
            <p>High-quality animatable avatar generation from texts via 3D-consistent occlusion-aware score distillation sampling, ready for 3D scene composition with diverse interactions.</p>
          </td>
        </tr>
      
      </table>

      <!-- Professional Service -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Professional Services</heading>
          <ul style="list-style-type: disc; padding-left: 20px; margin: 0;">
            <li style="margin: 10px 0;">
              Reviewer: NeurIPS 2025; ICCV 2025; ICLR 2025; CVPR 2025; ICML 2024; TPAMI; TIP; TMM; etc.
            </li>
            <li style="margin: 10px 0;">
              Teaching assistant: Embodied AI 101 (2025 Summer), HKU; Computer Vision (Fall 2022), USTC.
            </li>
          </ul>
        </td>
      </tr></tbody>

      <!-- Acknowledgement -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr><td>
          <br>
          <p align="center">
            <font size="2">
              Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron's website</a>.
            </font>
          </p>
        </td></tr></tbody>
      </table>
    
    </td></tr></tbody>
  </table>

</body></html>
